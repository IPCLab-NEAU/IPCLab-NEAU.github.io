<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0021)http://luchaochao.me/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head _wxlaelhepjgkhpnfpeodbobgikmbjecnne_="shake_1.0"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="keywords" content="Xue Yang, Perspective Ph.D. Student at ThinkLab"> 
<meta name="description" content="Xue Yang's Homepage">
<link rel="icon" type="image/png" href="images/icon.png">
<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
<title>Xue Yang - Homepage</title>
<script async="" src="./files/analytics.js"></script><script type="text/javascript" async="" src="./files/ga.js"></script><script type="text/javascript" async="" src="./files/ga(1).js"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39824124-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60895030-1', 'auto');
  ga('send', 'pageview');

</script></head>

<body>

<div id="layout-content" style="margin-top:25px">
<!-- <script type="text/javascript" async="" src="./jshao_files/ga.js"></script>-->
<script type="text/javascript"> 
// Toggle Display of BibTeX
function toggleBibtex(articleid) {
  var bib = document.getElementById(articleid);
  if (articleid=="Literature"){
  	var bib2 = document.getElementById("Literature");
  	bib2.style.display = "none";
  }
  if (articleid=="Album"){
  	var bib2 = document.getElementById("Album");
  	bib2.style.display = "none";
  }
  // Toggle 
    if(bib.style.display == "none") {
      bib.style.display = "";
    }
    else {
      bib.style.display = "none";
    }
}
</script>

<table>
	<tbody>
		<tr>
			<td>
				<img src="./images/yangxue.jpg" border="0" width="200">
			</td>
			<td width="50"></td>
			<td width="500">
				<div id="toptitle">					
				<h1>Xue Yang&nbsp;</h1>
				<h1><img src="./images/name.png" border="0" width="120"></h1>

				<p>
					<strong>Ph.D. Student at</strong>
					<a href="http://thinklab.sjtu.edu.cn/"><strong>ThinkLab</strong></a><br>
				</p>
				<p>
					<a href="http://www.cs.sjtu.edu.cn">Department of Computer Science and Engineering</a>, <br>
					<a href="http://ai.sjtu.edu.cn/">MoE Key Lab of Artificial Intelligence, AI Institute</a>, <br>
					Shanghai Jiao Tong University, <br>
					Shanghai, China 200240,<br>
					Email: yangxue-2019-sjtu@sjtu.edu.cn <br>
					Wechat: yangxue-0826 <br>
					<a href="./index.html">New Homepage</a>
					<!--<a href="https://yangxue.github.io/files/CV.pdf">[Curriculum Vitae]</a>--> 
				</p>
				<p>
					<a href="https://github.com/yangxue0827" target＝_blank><img src="./images/github.png"  border="0" width="30"></a>
					<a href="https://www.zhihu.com/people/flyyoung-68" target＝_blank><img src="./images/zhihu.png"  border="0" width="30"></a>
					<a href="https://scholar.google.com/citations?user=2xTlvV0AAAAJ&hl=zh-CN" target＝_blank><img src="./images/google_scholar.png"  border="0" width="30"></a>
				</p>
			</td>
		</tr>
	</tbody>
</table>


<h2>Biography</h2>
<p>
	Xue Yang is now a Ph.D. student in <a href="https://news.sjtu.edu.cn/jdyw/20190930/111855.html">Wu Honor Class</a>, <a href="http://www.cs.sjtu.edu.cn">Department of Computer Science and Engineering</a>,
	<a href="http://en.sjtu.edu.cn">Shanghai Jiao Tong University</a> starting from Autumn 2019. 
	His research advisor is <a href="http://thinklab.sjtu.edu.cn/">Prof. Junchi Yan</a>.
</p>
<p>
	Xue Yang received the B. E. degree from School of Information Science and Engineering, <a href="http://www.csu.edu.cn/">Central South University</a>, Hunan, China, in 2016. He received the M. S. degree from <a href="https://eece.ucas.ac.cn/index.php/zh-cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a> (<a href="http://aircas.ac.cn/">Institute of Electrics, Chinese Academy of Sciences</a>), Beijing, China, in 2019. Previously, he was a research intern in <a href="https://www.megvii.com/">Megvii Detection Team</a>, Beijing, China, in 2019. 
</p>
<p>Xue Yang's research interests include deep learning and computer vision, with a focus on generic object detection, aerial imagery detection, and scene text detection.
</p>

<h2>News</h2>
	<li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        07 / 2020: &nbsp; One paper is accepted by <b>ECCV 2020</b>
    </li>

	<li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        09 / 2019: &nbsp; I'm supported by Wu Wen Jun Honorary Doctoral Scholarship, AI Institute, Shanghai Jiao Tong University
    </li>

	<li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        09 / 2019: &nbsp; I'm joining Department of CSE at Shanghai Jiao Tong University as a PhD student
    </li>

	<li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        07 / 2019: &nbsp; One paper is accepted by <b>ICCV 2019</b>
    </li>

	<li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        07 / 2019: &nbsp; One paper is accepted by <b>BMVC 2019</b>
    </li>

    <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        06 / 2019: &nbsp; We win 1st place in <a href="https://gaia.didichuxing.com/d2city">WAD2019 Challenge</a> on the D<sup>2</sup>-City & BDD100K Detection Domain Adaption track
    </li>

    <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        06 / 2019: &nbsp; We win 3st/4th place in <a href="https://captain-whu.github.io/DOAI2019/results.html">DOAI2019 Challenge</a> on the HBB/OBB track 
    </li>


<h2>Publications</h2>
<h3>Conference</h3>
<table style="width:100%" cellspacing="10" valign="top">
	<tr>
	<td><img src="./images/csl.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://arxiv.org/abs/2003.05597"> <font size=4>Arbitrary-Oriented Object Detection with Circular Smooth Label</font> </a> <br> 
		<b>Xue Yang</b>, Junchi Yan.<br>
		In <em>Proceedings of the European Conference on Computer Vision <font color="red"><b>(ECCV2020, CCF-B)</b></font></em>, Glasgow, Scotland, UK, 2020 <br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://arxiv.org/pdf/2003.05597.pdf"><font color="blue">paper</font></a>&nbsp;&nbsp;  
		<img src="./images/pdf.png"  border="0" width="15"> <a href="./files/csl_slides.pdf"><font color="blue">slides</font></a><br>
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow"><font color="blue">code</font></a><br>
		<img src="./images/zhihu.png"  border="0" width="15"> <a href="https://zhuanlan.zhihu.com/p/111493759"><font color="blue">解读</font></a><br>
	</td>
	</tr>

	<tr>
	<td><img src="./images/scrdet.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://arxiv.org/abs/1811.07126"> <font size=4>SCRDet: Towards More Robust Detection for Small, Cluttered and Rotated Objects </font>  </a> <br> 
		<b>Xue Yang</b>, Jirui Yang, Junchi Yan, Yue Zhang, Tengfei Zhang, Zhi Guo, Sun Xian, Kun Fu.<br>
		In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV2019, CCF-A)</b></font></em>, Seoul, Korea, 2019 <br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_SCRDet_Towards_More_Robust_Detection_for_Small_Cluttered_and_Rotated_ICCV_2019_paper.pdf"><font color="blue">paper</font></a>&nbsp;&nbsp;  
		<img src="./images/pdf.png"  border="0" width="15"> <a href="./files/iccv_2019_yx_poster.pdf"><font color="blue">poster</font></a><br>
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation"><font color="blue">code: IoU-Smooth L1 Loss</font></a>   &nbsp;&nbsp;  
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow"><font color="blue">code: R<sup>2</sup>CNN++</font></a><br>
		<img src="./images/zhihu.png"  border="0" width="15"> <a href="https://zhuanlan.zhihu.com/p/107400817"><font color="blue">解读</font></a><br>
	</td>
	</tr>
	
	<tr>
	<td><img src="./images/bmvc2019.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://arxiv.org/abs/1907.11914"> <font size=4>Rethinking Classification and Localization for Cascade R-CNN </font>  </a> <br>  
		Ang Li, <b>Xue Yang</b>, Chongyang Zhang.<br>
		In <em>Proceedings of the 30th British Machine Vision Conference <font color="red"><b>(BMVC2019, CCF-C)</b></font></em>, Cardiff, Wales, UK, 2019 <br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://arxiv.org/pdf/1907.11914.pdf"><font color="blue">paper</font></a><br>
	</td>
	</tr>
</table>

<h3>Journal</h3>
<table style="width:100%" cellspacing="10" valign="top">
	<tr>
	<td><img src="./images/access.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://ieeexplore.ieee.org/document/8464244"> <font size=4>Position Detection and Direction Prediction for Arbitrary-Oriented Ships via Multitask Rotation Region Convolutional Neural Network </font> </a> <br> 
		<b>Xue Yang</b>, Hao Sun, Xian Sun, Menglong Yan, Zhi Guo, Kun Fu.<br>
		In <em>Access</em>, 2018 <br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://ieeexplore.ieee.org/document/84642442"><font color="blue">paper</font></a><br>
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/yangxue0827/R2CNN_HEAD_FPN_Tensorflow"><font color="blue">code</font></a><br>
	</td>
	</tr>

	<tr>
	<td><img src="./images/DCMSNN.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://ieeexplore.ieee.org/document/8334534"> <font size=4>A Densely Connected End-to-End Neural Network for Multiscale and Multiscene SAR Ship Detection </font> </a> <br> 
		Jiao Jiao, Yue Zhang, Hao Sun, <b>Xue Yang</b>, Xun Gao, Wen Hong, Kun Fu, Xian Sun.<br>
		In <em>Access</em>, 2018 <br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://ieeexplore.ieee.xilesou.top/abstract/document/8334534"><font color="blue">paper</font></a><br>
	</td>

	<tr>
	<td><img src="./images/rdfpn.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://www.mdpi.com/2072-4292/10/1/132"> <font size=4>Automatic Ship Detection in Remote Sensing Images from Google Earth of Complex Scenes Based on Multiscale Rotation Dense Feature Pyramid Networks </font> </a> <a href="http://apps.webofknowledge.com/"><font color="red"><b>(ESI Highly Cited Papers)</b></font></a> <br>
		<b>Xue Yang</b>, Hao Sun, Kun Fu, Jirui Yang, Xian Sun, Menglong Yan, Zhi Guo.<br>
		In <em>Remote Sensing</em>, 2018 <br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://www.mdpi.com/2072-4292/10/1/132"><font color="blue">paper</font></a><br>
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/yangxue0827/R-DFPN_FPN_Tensorflow"><font color="blue">code</font></a><br>
	</td>
	</tr>
</table>

<h2>Preprints</h2>
<table style="width:100%" cellspacing="10" valign="top">
	
	<tr>
	<td><img src="./images/scrdet++.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://arxiv.org/abs/2004.13316"> <font size=4>SCRDet++: Detecting Small, Cluttered and Rotated Objects via Instance-Level Feature Denoising and Rotation Loss Smoothing</font> </a> <br> 
		<b>Xue Yang</b>, Junchi Yan, Xiaokang Yang, Jin Tang, Wenlong Liao, Tao He.<br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://arxiv.org/pdf/2004.13316.pdf"><font color="blue">paper</font></a><br>
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation"><font color="blue">code: IoU-Smooth L1 Loss</font></a>   &nbsp;&nbsp;  
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/Thinklab-SJTU/R3Det_Tensorflow"><font color="blue">code: R<sup>3</sup>Det++</font></a> &nbsp;&nbsp;  
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/SJTU-Thinklab-Det/DOTA-DOAI"><font color="blue">code: DOTA-DOAI</font></a><br>
		<img src="./images/dataset.png"  border="0" width="15"> <a href="https://github.com/Thinklab-SJTU/S2TLD"><font color="blue">dataset: S<sup>2</sup>TLD</font></a><br>
		<img src="./images/project.png"  border="0" width="15"> <a href="./SCRDet++.html"><font color="blue">project page</a><br>
	</td>
	</tr>

	<tr>
	<td><img src="./images/rsdet.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://arxiv.org/abs/1911.08299"> <font size=4>Learning Modulated Loss for Rotated Object Detection </font>  </a> <br> 
		Wen Qian, <b>Xue Yang</b>, Silong Peng, Yue Guo, Junchi Yan.<br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://arxiv.org/pdf/1911.08299.pdf"><font color="blue">paper</font></a><br>
		<img src="./images/zhihu.png"  border="0" width="15"> <a href="https://zhuanlan.zhihu.com/p/108185873"><font color="blue">解读</font></a><br>
	</td>
	</tr>

	<tr>
	<td><img src="./images/r3det.png" border="0" width="220"></td>
	<td valign="top" align='left'>
		<a href="https://arxiv.org/abs/1908.05612"> <font size=4>R<sup>3</sup>Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object</font> <br></a> 
		<b>Xue Yang</b>, Qingqing Liu, Junchi Yan, Ang Li, Zhiqiang Zhang, Gang Yu.<br>
		<img src="./images/pdf.png"  border="0" width="15"> <a href="https://arxiv.org/pdf/1908.05612.pdf"><font color="blue">paper</font> </a> <br>  
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/Thinklab-SJTU/R3Det_Tensorflow"><font color="blue">R<sup>3</sup>Det-TF</font></a> &nbsp;&nbsp;  
		<img src="./images/github.png"  border="0" width="15"> <a href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection"><font color="blue">R<sup>3</sup>Det-Pytorch</font></a>
	</td>
	</tr>

</table>

<div class="widgetContainer" style="width:300px; margin: 0 auto;">				
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=yZcblN50sSwsCOVmEPYqkPD6Wo-RFHx0E2yb6Ktm_Wk&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
</div>

<div class="pure-u-1 pure-u-md-4-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Xue Yang's Homepage.</a> </div></div>


</body></html>
